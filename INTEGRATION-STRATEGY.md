# Integration Strategy

## Overview

The Command Center architecture **fully supports** all requested integrations:

‚úÖ **Training Programs** (Sales, Vibe Coding, Storytelling)
‚úÖ **Task Management Sync** (Notion, Asana, Linear, etc.)
‚úÖ **AI Voice Input** (OpenAI Whisper)

**Current Status**: All API interfaces defined, implementation adapters pending.

---

## 1. Training Programs

### Architecture Support

**API Interface**: `learning.api.ts` ‚úÖ Complete

```typescript
export interface Curriculum {
  id: string;
  slug: string; // 'sales-month-01', 'vibe-coding'
  title: string;
  description: string;
  duration: number; // 30 days
  category: CurriculumCategory;
  lessons: Lesson[];
}

export interface LearningProgress {
  curriculumId: string;
  currentDay: number;
  completedLessons: number[];
  streak: number;
  status: "active" | "paused" | "completed";
}
```

### Implementation Plan

**Phase 1: localStorage** (MVP)

1. Create `localStorage/learning.service.ts`
2. Store curricula and progress locally
3. Manual curriculum creation (JSON files)

**Phase 2: Supabase** (Scalable)

1. Create `supabase/learning.service.ts`
2. Store curricula in Supabase
3. User-generated curricula sharing (future)

**Phase 3: AI Enhancement**

1. Auto-generate lessons from topics
2. Adaptive difficulty
3. Personalized recommendations

### Data Model

```
Curricula (Static Content)
‚îî‚îÄ‚îÄ Sales Training - Month 01
    ‚îú‚îÄ‚îÄ Day 1: Customer Psychology Fundamentals
    ‚îú‚îÄ‚îÄ Day 2: Discovery Call Framework
    ‚îú‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ Day 30: Objection Handling Master Class

Progress Tracking (Per User)
‚îî‚îÄ‚îÄ User: amk
    ‚îî‚îÄ‚îÄ Sales Training - Month 01
        ‚îú‚îÄ‚îÄ Current Day: 5
        ‚îú‚îÄ‚îÄ Completed: [1, 2, 3, 4, 5]
        ‚îú‚îÄ‚îÄ Streak: 5 days
        ‚îî‚îÄ‚îÄ Notes: ["Day 1: Cognitive biases...", ...]
```

---

## 2. Task Management Integration

### Architecture Support

**API Interface**: `task-sync.api.ts` ‚úÖ Complete

### Your Vision (Confirmed)

> **Personal tasks**: Can be updated FROM Command Center (bidirectional)
> **Team tasks**: READ-ONLY from PM tools (team uses their tools)

**‚úÖ Infrastructure Supports This Exactly**

### How It Works

```typescript
// Personal Workspace (Notion) - BIDIRECTIONAL
const personalWorkspace: WorkspaceConfig = {
  name: "Personal Projects",
  type: "notion",
  syncDirection: "bidirectional", // ‚úÖ Can write back
  isPersonal: true, // ‚úÖ User owns this
  filters: { assignedToMe: true },
};

// Team Workspace (Asana) - READ-ONLY
const teamWorkspace: WorkspaceConfig = {
  name: "Team Sprint Board",
  type: "asana",
  syncDirection: "read-only", // ‚úÖ Only import
  isPersonal: false, // ‚úÖ Team workspace
  filters: { assignedToMe: true },
};
```

### Sync Behavior

**Bidirectional (Personal)**:

- ‚úÖ Import tasks from Notion ‚Üí Command Center
- ‚úÖ Create tasks in Command Center ‚Üí Export to Notion
- ‚úÖ Update tasks in Command Center ‚Üí Update in Notion
- ‚úÖ Conflict resolution (choose local or remote)

**Read-Only (Team)**:

- ‚úÖ Import tasks from Asana ‚Üí Command Center
- ‚ùå Changes in Command Center DO NOT sync back
- ‚úÖ View team tasks in unified dashboard
- ‚úÖ Auto-refresh on schedule (e.g., every 15 min)

### Implementation Priority

**Phase 1: Notion Integration** (Most Common)

1. `notion/task-sync.service.ts`
2. OAuth authentication
3. Bidirectional sync with conflict resolution
4. Task mapping (local ‚Üî Notion)

**Phase 2: Asana Integration** (Team Sync)

1. `asana/task-sync.service.ts`
2. API key authentication
3. Read-only import
4. Auto-refresh scheduler

**Phase 3: Other Tools**

- Linear (read-only)
- Jira (read-only)
- Todoist (bidirectional)
- ClickUp (read-only)

### Conflict Resolution

When bidirectional sync detects conflicts:

```typescript
interface TaskConflict {
  field: "title" | "status" | "dueDate";
  localValue: string;
  externalValue: string;
  timestamp: string;
}

// User chooses resolution
await taskSyncService.resolveConflict(conflictId, "local"); // Keep local
await taskSyncService.resolveConflict(conflictId, "external"); // Keep external
await taskSyncService.resolveConflict(conflictId, "merge"); // Smart merge
```

### Status Mapping

Command Center uses Warren Buffett 25/5 categories. External tools use different statuses.

**Automatic Conversion**:

```typescript
// Notion ‚Üí Command Center
'To Do' ‚Üí 'braindump'
'In Progress' ‚Üí 'priority'
'Done' ‚Üí (archived, not shown)

// Asana ‚Üí Command Center
'Later' ‚Üí 'parking'
'Today' ‚Üí 'priority'
'Completed' ‚Üí (archived)
```

---

## 3. AI Voice Input (Whisper)

### Architecture Support

**API Interface**: `transcription.api.ts` ‚úÖ Complete

### Recommended Provider

**OpenAI Whisper API**

**Why?**

- ‚úÖ Production-ready (99.9% uptime SLA)
- ‚úÖ Highly accurate (multi-language)
- ‚úÖ Cost-effective ($0.006/minute = $0.36/hour)
- ‚úÖ Fast processing (~10 seconds for 1 minute audio)
- ‚úÖ Easy integration (REST API)
- ‚úÖ Structured data extraction via GPT-4

**Alternatives**:

- Local Whisper (privacy, slower, no API key needed)
- Google Speech-to-Text (streaming, more expensive)
- Azure Speech (enterprise compliance)

### Use Cases

**1. Morning Review Voice Input**

```typescript
// User records 2-minute voice note
const audio = await recordAudio();

// Transcribe
const result = await transcriptionService.transcribe({ audio });

// Extract structured data
const data = await transcriptionService.extractStructuredData(
  result.text,
  "habits",
);

// Auto-populate form
morningReview.sleep.quality = data.sleepQuality;
morningReview.energy = data.energyLevel;
morningReview.intentions = data.intentions;
```

**2. Quick Task Creation**

```typescript
// User: "Add task: Call John about the sales pitch tomorrow at 3pm"

const result = await transcriptionService.extractStructuredData(
  voiceInput,
  'tasks'
);

// Auto-creates task
{
  text: "Call John about the sales pitch",
  dueDate: "2026-02-12T15:00:00",
  category: "priority"
}
```

**3. Gratitude Journaling**

```typescript
// User: "I'm grateful for sunny weather because it made
//        the walk with the kids enjoyable. And for
//        closing the deal with the new client."

const data = await transcriptionService.extractStructuredData(
  voiceInput,
  "gratitude",
);

// Result:
[
  { thing: "sunny weather", why: "walk with kids enjoyable" },
  { thing: "closing deal with new client", why: "" },
];
```

### Implementation Plan

**Phase 1: OpenAI Whisper**

1. Create `openai/transcription.service.ts`
2. File-based transcription (upload audio file)
3. Structured data extraction (use GPT-4 for parsing)

**Phase 2: Real-Time Streaming**

1. Browser microphone capture
2. Stream audio chunks to Whisper
3. Partial results displayed in real-time

**Phase 3: Offline Support**

1. Download Whisper model locally (optional)
2. Fallback to local when no internet
3. Sync transcriptions when online

### Cost Estimation

**OpenAI Whisper Pricing**: $0.006/minute

**Typical Usage**:

- Morning review: 2 min = $0.012
- Evening review: 2 min = $0.012
- Quick task: 10 sec = $0.001
- **Daily total: ~$0.025**
- **Monthly total: ~$0.75**

**Very affordable for personal use!**

---

## Infrastructure Readiness Summary

### ‚úÖ **YES** - Infrastructure Fully Supports All Integrations

**What's Complete**:

1. ‚úÖ Hexagonal architecture (ports & adapters)
2. ‚úÖ API interfaces defined (Learning, TaskSync, Transcription)
3. ‚úÖ Service layer pattern established
4. ‚úÖ Type-safe contracts (TypeScript interfaces)
5. ‚úÖ Result pattern for error handling
6. ‚úÖ Pluggable adapter design

**What's Needed (Implementations)**:

1. `localStorage/learning.service.ts` - Training programs
2. `notion/task-sync.service.ts` - Notion integration
3. `asana/task-sync.service.ts` - Asana integration
4. `openai/transcription.service.ts` - Whisper API

**Zero Architecture Changes Required**

The infrastructure is **production-ready** for these integrations. Adding them only requires:

- Implementing the adapters (follows existing patterns)
- Adding API credentials (environment variables)
- Creating UI components (Voice button, Sync settings)

---

## Migration Path Example: Adding Whisper

### Step 1: Create Adapter

```typescript
// src/lib/api/implementations/openai/transcription.service.ts
import type { TranscriptionAPI } from '$lib/api/interfaces/transcription.api';

class OpenAITranscriptionService implements TranscriptionAPI {
  async transcribe(request) {
    const formData = new FormData();
    formData.append('file', request.audio);
    formData.append('model', 'whisper-1');

    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${process.env.OPENAI_API_KEY}` },
      body: formData
    });

    const data = await response.json();
    return { success: true, data: { text: data.text, ... } };
  }

  // ... implement other methods
}

export const openAITranscription = new OpenAITranscriptionService();
```

### Step 2: Export Service

```typescript
// src/lib/services/transcription.service.ts
import { openAITranscription } from "$lib/api/implementations/openai/transcription.service";

export const transcriptionService = openAITranscription;
```

### Step 3: Use in Components

```svelte
<!-- MorningTab.svelte -->
<script>
  import { transcriptionService } from '$lib/services/transcription.service';

  async function handleVoiceInput() {
    const audio = await recordAudio();
    const result = await transcriptionService.transcribe({ audio });

    // Extract structured data
    const data = await transcriptionService.extractStructuredData(
      result.data.text,
      'habits'
    );

    // Populate form
    sleepQuality = data.sleepQuality;
    energy = data.energyLevel;
  }
</script>

<button onclick={handleVoiceInput}>üé§ Voice Input</button>
```

**That's it!** Zero changes to existing code.

---

## Best Practices

### 1. Environment Variables

```bash
# .env.local
OPENAI_API_KEY=sk-...
NOTION_API_KEY=secret_...
ASANA_API_KEY=...
```

### 2. Error Handling

All integrations use the `Result<T>` pattern:

```typescript
const result = await transcriptionService.transcribe({ audio });

if (!result.success) {
  console.error(result.error);
  // Show user-friendly error
  return;
}

// Use result.data
const transcription = result.data;
```

### 3. Rate Limiting

```typescript
// OpenAI: 50 requests/minute
// Notion: 3 requests/second
// Asana: 150 requests/minute

// All handled in adapter implementations
```

### 4. Caching

```typescript
// Cache transcriptions locally
await localStorageService.set(`transcription-${id}`, result);

// Avoid re-transcribing same audio
const cached = await localStorageService.get(`transcription-${id}`);
if (cached) return cached;
```

---

## Timeline Estimates

**Not including timelines (per user preference)**, but rough complexity:

### Learning API (localStorage)

- **Complexity**: Low-Medium
- **Dependencies**: None
- **Tasks**: Service implementation, UI components, sample curricula

### Notion TaskSync

- **Complexity**: Medium-High
- **Dependencies**: Notion API SDK, OAuth flow
- **Tasks**: Service implementation, sync logic, conflict resolution UI

### Whisper Integration

- **Complexity**: Low-Medium
- **Dependencies**: OpenAI API key
- **Tasks**: Service implementation, audio recording UI, data extraction

---

## Conclusion

**‚úÖ Infrastructure is 100% ready for all integrations**

The hexagonal architecture you requested ("Keep it modular API first") was the **perfect choice** for these integrations:

1. **Learning Programs**: Interface defined, just implement adapter
2. **Task Sync**: Interface supports your exact vision (bidirectional personal, read-only team)
3. **AI Voice**: Interface ready for Whisper or any provider

**No refactoring needed.** Just implement the adapters and build UI.

---

**Last Updated**: 2026-02-11
**Architecture Pattern**: Hexagonal (Ports & Adapters)
**Integration Readiness**: Production-Ready
